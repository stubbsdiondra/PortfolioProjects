---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Wine Quality Classification
#### Diondra Stubbs
#### CSC 310 Assignment 7
#### 2022 October 26

+++

## Dataset Description

This dataset is the result of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. More about this dataset: https://archive.ics.uci.edu/ml/datasets/wine

#### Dataset Features
1. Alcohol
2. Malic acid
3. Ash
4. Alcalinity of ash  
5. Magnesium
6. Total phenols
7. Flavanoids
8. Nonflavanoid phenols
9. Proanthocyanins
10. Color intensity
11. Hue
12. OD280/OD315 of diluted wines
13. Proline

```{code-cell} ipython3
#imports
import pandas as pd
import seaborn as sns
import numpy as np
from sklearn import tree
from sklearn import metrics as skmetrics
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
```

```{code-cell} ipython3
wine_quality_url = 'https://raw.githubusercontent.com/rhodyprog4ds/07-classification-stubbsdiondra/main/wine.data?token=GHSAT0AAAAAAB2K2A2ATUZW2BJ3OLPZBJLEY2ZPKYQ'
wine_df = pd.read_csv(wine_quality_url)
```

```{code-cell} ipython3
columns = ['quality','Alcohol','Malic_acid','Ash','Alcalinity',
          'Magnesium','Total_phenols','Flavanoids',
          'Nonflavanoid_phenols','Proanthocyanins',
          'Color_intensity','Hue','OD280_OD315',
          'Proline']

wine_df = wine_df = pd.read_csv(wine_quality_url, names = columns, sep = ',', header = None)
```

```{code-cell} ipython3
wine_df
```

## Classification Task
The task is to predict the quality of the wine from the measurements. I am going to attempt building an automatic eine classifier that, for measurements of a new wine returns the predicted quality. 

The DataFrame has columns for quality, alcohol,	malic acid, ash, alcalinity, magnesium, total_phenols, flavanoids, nonflavanoid_phenols, proanthocyanins, color intensity, hue, OD280_OD315, and proline. The target variable (chosen classifier) will be the quality of the wine.

```{code-cell} ipython3
feature_vars = features
target_var = 'quality'
```

## Exploratory Data Analysis

```{code-cell} ipython3
wine_df.info()
```

```{code-cell} ipython3
wine_df.describe()
```

```{code-cell} ipython3
wine_df['quality'].value_counts()
```

Here we will look at the distribution of features. This pair plot shows the distribution of the target variable quality. 

There is not a ton of overlap for the different qualities of each wine. I would like to assume that the data is reasonably seperable. The features mostly are shaped like symmetrical bell curves and their are no skewed distributions. Therefore the features are normally (Gaussian) distributed. 

```{code-cell} ipython3
sns.pairplot(data = wine_df, hue = target_var)
```

Gaussian Naive Bayes is a more reasonable model since the features are normally distributed.

+++

## Classification

```{code-cell} ipython3
X_train, X_test, y_train, y_test = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.5, random_state=0)
```

```{code-cell} ipython3
X_test.shape
```

```{code-cell} ipython3
X_train.head()
```

```{code-cell} ipython3
wine_df.head()
```

```{code-cell} ipython3
X_train.shape, wine_df.shape
```

```{code-cell} ipython3
89/178
```

We get 50% of the samples in the training set

```{code-cell} ipython3
gnb = GaussianNB()
```

```{code-cell} ipython3
gnb.__dict__
```

```{code-cell} ipython3
gnb.fit(X_train,y_train)
```

Fitting the Gaussian Naive Bayes

```{code-cell} ipython3
gnb.__dict__
```

```{code-cell} ipython3
# Using EDA to find the mean and variance of each feature for each quality
wine_grouped = wine_df.groupby('quality')
```

```{code-cell} ipython3
wine_grouped[columns].mean()
```

```{code-cell} ipython3
wine_grouped[columns].var()
```

This model has an accuracy score of ~ 94%.

```{code-cell} ipython3
gnb.fit(X_train,y_train)
gnb.score(X_test,y_test)
```

```{code-cell} ipython3
y_pred = gnb.predict(X_test)
```

```{code-cell} ipython3
confusion_matrix(y_test, y_pred) 
```

This Gaussian Naive Bayes Classifier model works well meaning that the parameters fit the data well.

```{code-cell} ipython3
# generating synthetic data
N = 20
gnb_df = pd.DataFrame(np.concatenate([np.random.multivariate_normal(th, sig*np.eye(13),N)
         for th, sig in zip(gnb.theta_,gnb.sigma_)]),
         columns = feature_vars)
gnb_df['quality'] = [ci for cl in [[c]*N for c in gnb.classes_] for ci in cl]
```

```{code-cell} ipython3
gnb_df.head()
```

```{code-cell} ipython3
sns.pairplot(data =gnb_df, hue='quality')
```

This looks pretty close to the actual data, though there is more overlap for the different qualities in each scatter plot. This means that the naive assumption doesnâ€™t hold perfectly on this data.

The parameters do generate similar synthetic data.

+++

What if we used a Decision Tree?

```{code-cell} ipython3
dt = tree.DecisionTreeClassifier()
```

```{code-cell} ipython3
dt.fit(X_train,y_train)
```

```{code-cell} ipython3
dt.score(X_test,y_test)
```

The accuracy score is lower. Therefore the Gaussian Naive Bayes was a more reasonable model.

+++

##### Repeat the split, train, and test steps 5 times to use 5 different random splits of the data, save the scores into a dataframe. Compute the mean and std of the scores.

```{code-cell} ipython3
X_train1, X_test1, y_train1, y_test1 = train_test_split(wine_df[feature_vars],wine_df[target_var], random_state=0)
```

```{code-cell} ipython3
X_train1.head()
```

```{code-cell} ipython3
X_train1.shape, wine_df.shape
```

```{code-cell} ipython3
133/178
```

We can see that we get ~75% of the samples in the training set

```{code-cell} ipython3
gnb.fit(X_train1,y_train1)
```

```{code-cell} ipython3
y_pred = gnb.predict(X_test1)
```

```{code-cell} ipython3
gnb.score(X_test1,y_test1)
```

```{code-cell} ipython3
X_train2, X_test2, y_train2, y_test2 = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.33, random_state=0)
```

```{code-cell} ipython3
X_train2.shape, wine_df.shape
```

```{code-cell} ipython3
119/178
```

We get ~69% of the samples in the training set

```{code-cell} ipython3
y_pred = gnb.predict(X_test2)
gnb.score(X_test2,y_test2)
```

```{code-cell} ipython3
X_train3, X_test3, y_train3, y_test3 = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.75, random_state=0)
X_train3.shape, wine_df.shape
```

```{code-cell} ipython3
44/178
```

We get ~25% of the samples in the training set

```{code-cell} ipython3
y_pred = gnb.predict(X_test3)
gnb.score(X_test3,y_test3)
```

```{code-cell} ipython3
X_train4, X_test4, y_train4, y_test4 = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.90, random_state=0)
X_train4.shape, wine_df.shape
```

```{code-cell} ipython3
17/178
```

We get ~10% of the samples in the training set

```{code-cell} ipython3
y_pred = gnb.predict(X_test4)
gnb.score(X_test4,y_test4)
```

```{code-cell} ipython3
X_train5, X_test5, y_train5, y_test5 = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.22, random_state=0)
X_train5.shape, wine_df.shape
```

```{code-cell} ipython3
138/178
```

We get ~78% of the samples in the training set

```{code-cell} ipython3
y_pred = gnb.predict(X_test5)
gnb.score(X_test5,y_test5)
```

It seems that the closer you are to 25% samples, the higher accuracy score you get for the classifier model. At 25% of samples, the score is 97%.

+++

#### Saving the scores into a dataframe

```{code-cell} ipython3
data = [gnb.score(X_test1,y_test1), gnb.score(X_test2,y_test2), gnb.score(X_test3,y_test3), gnb.score(X_test4,y_test4), gnb.score(X_test5,y_test5)]
```

```{code-cell} ipython3
df = pd.DataFrame(data, columns = ['Accuracy Scores'])
df
```

```{code-cell} ipython3
df['Accuracy Scores'].mean()
```

```{code-cell} ipython3
df['Accuracy Scores'].std()
```

The mean of the accuracy scores is ~95% which is fairly close to the accuracy score of the original model with 50% of the data. The standard deviation is fairly small indicating that the values tend to be close to the mean, thus very reliable. 

I believe that this model is good enough for real use since the classification accuracy score is high. Howver, I would seek alternative models that would give an even better classification score indicating an even better classifier. 

+++

## Exploring Problem Setups

```{code-cell} ipython3
X_train10, X_test10, y_train10, y_test10 = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.10, random_state=0)
X_train10.shape, X_test10.shape, wine_df.shape
```

```{code-cell} ipython3
d1 = gnb.score(X_train10,y_train10)
d1
```

```{code-cell} ipython3
d2 = gnb.score(X_test10,y_test10)
d2
```

```{code-cell} ipython3
X_train30, X_test30, y_train30, y_test30 = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.30, random_state=0)
X_train30.shape, X_test30.shape, wine_df.shape
```

```{code-cell} ipython3
d3 = gnb.score(X_train30,y_train30)
d3
```

```{code-cell} ipython3
d4 = gnb.score(X_test30,y_test30)
d4
```

```{code-cell} ipython3
X_train90, X_test90, y_train90, y_test90 = train_test_split(wine_df[feature_vars],wine_df[target_var], test_size = 0.90, random_state=0)
X_train90.shape, X_test90.shape, wine_df.shape
```

```{code-cell} ipython3
d5 = gnb.score(X_train90,y_train90)
d5
```

```{code-cell} ipython3
d6 = gnb.score(X_test90,y_test90)
d6
```

```{code-cell} ipython3
data2 = {'train_pct':[.10, .30, .90],'n_train_samples':[160, 124,17], 'n_test_samples':[18,54,161], 
         'train_acc':[d1,d3,d5], 'test_acc':[d2,d4,d6]}
```

```{code-cell} ipython3
explore_df = pd.DataFrame(data2)
```

```{code-cell} ipython3
explore_df
```

```{code-cell} ipython3
explore_df.plot( x='train_acc', y ='train_pct')
```

```{code-cell} ipython3
explore_df.plot( x='test_acc', y ='train_pct')
```

When the training percentage is increased, the test samples increase and the train samples decrease. As the training percentage increases, the training accuracy is better than the test accuracy even though both are increasing.
